---
title: "billboard_scrape"
author: "Louise Brix Pilegaard Hansen"
date: '2022-12-05'
output: html_document
---

This markdown includes code to scrape the Billboard Hot 100 chart from billboard.com and extracting song lyrics from genius.com. Topic Modelling of the lyrics data can be found in the markdown "billboard_tm.Rmd".

**NOTE**: Throughout this script, all "write_csv" commands have been commented out. This is to not overwrite the .csv files used for the Topic Modeling analysis, as running the functions from the geniusr packages sometimes cause unexpected and unsolvable errors with the API. In order to replicate the exact results of this project, it is recommended to use the .csv files provided in the GitHub repo. 


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r loading packages, message=FALSE, warning=FALSE}
#install.packages('rvest')
#install.packages('tidyverse')
#install.packages('geniusr')
library(rvest)
library(tidyverse)
library(geniusr)
```

# Scraping billboard.com

### Define function to scrape billboard.com
```{r define scraper function}
billboard_scraper <- function(url){
  
  # reading the url
  url_html <- read_html(url)
  
  # the information to be extracted is nested in a html "list" element
  entries <- url_html %>% 
    html_elements("li")
  
  # this scrapes the song titles, looking for information in the html class "c-title"
  titles <- entries %>% 
    html_elements(".c-title") %>% 
    html_text2() 
  
  # this scrapes the artists, looking for information in the html class "c-label.a-no-trucate"
  artists <- url_html %>%
    html_nodes(".c-label.a-no-trucate") %>%
    html_text2()
  
  # saving as a dataframe
  return(data.frame(title = titles, artist = artists))
}
```

### Define the URLs to be scraped

The URL of the charts from the first week of January, April, July and October in 1982, 2002 and 2022 is saved

```{r define URLs}
# pick weeks and years 
urls_1982 <- c("https://www.billboard.com/charts/hot-100/1982-01-09/", "https://www.billboard.com/charts/hot-100/1982-04-10/", "https://www.billboard.com/charts/hot-100/1982-07-10/", "https://www.billboard.com/charts/hot-100/1982-10-09/")

urls_2002 <- c("https://www.billboard.com/charts/hot-100/2002-01-12/", "https://www.billboard.com/charts/hot-100/2002-04-13/", "https://www.billboard.com/charts/hot-100/2002-07-13/", "https://www.billboard.com/charts/hot-100/2002-10-12/")

urls_2022 <- c("https://www.billboard.com/charts/hot-100/2022-01-08/", "https://www.billboard.com/charts/hot-100/2022-04-09/", "https://www.billboard.com/charts/hot-100/2022-07-09/", "https://www.billboard.com/charts/hot-100/2022-10-08/")
```


### Applying the scraping function and saving to csv files
```{r scrape billboard URLs}

playlist_1982 <- lapply(urls_1982, billboard_scraper)
playlist_1982 <- do.call(rbind, playlist_1982) # combining all the df's from one year into one
playlist_1982$year <- "1982" # adding the year
#write_csv(playlist_1982, "playlist_1982.csv")

playlist_2002 <- lapply(urls_2002, billboard_scraper)
playlist_2002 <- do.call(rbind, playlist_2002)
playlist_2002$year <- "2002"
#write_csv(playlist_2002, "playlist_2002.csv")

playlist_2022 <- lapply(urls_2022, billboard_scraper)
playlist_2022 <- do.call(rbind, playlist_2022)
playlist_2022$year <- "2022"
#write_csv(playlist_2022, "playlist_2022.csv")
```


# Getting lyrics from genius.com using the Genius API 

I have created an environment variable containing my personal API token to genius.com. This key cannot be shared; to create your own, go to https://genius.com/api-clients.

This token must be saved in an .Renviron as 'GENIUS_API_TOKEN' file in the correct directory on your machine (see https://stackoverflow.com/questions/40788645/how-to-create-renviron-file for different solutions for Windows, Linux and Mac).

### Activate Genius API token
```{r echo = T, results = 'hide'}
Sys.getenv('GENIUS_API_TOKEN') # getting the value of environment variable containing the API token
genius_token() # activate token
```


### Read in all the songs
```{r reading in data, message=FALSE}
playlist_1982 <- read_csv("playlist_1982.csv")
playlist_2002 <- read_csv("playlist_2002.csv")
playlist_2022 <- read_csv("playlist_2022.csv")

playlists <- list(playlist_1982, playlist_2002, playlist_2022)
```

### Cleaning the data

The package geniusr requires the name of the artist to be typed in a way that is compatible with genius.com's search engine. This requires some cleaning of the "artist" column

```{r data cleaning}
# defining the cleaning function
playlist_clean <- function(df){
  # replace "&", "X" and "," with "and"
  df$artist <- str_replace_all(df$artist, "&", "and") 
  df$artist <- str_replace_all(df$artist, "(\\s[xX]\\s)", " and ")
  df$artist <- str_replace_all(df$artist, ",", " and")
  
  # remove the word featuring and everything after it
  df$artist <- str_replace_all(df$artist, "((Featuring))(?s)(.*$)", "")
  return(df)
}

playlists <- lapply(playlists, playlist_clean)

# there is an artist in the 2022 called "Lil Nas X". The cleaning function have altered his name to "Lil Nas and." Adding his name back to the data
playlists[[3]]$artist <- str_replace_all(playlists[[3]]$artist, "Lil Nas and", "Lil Nas X")
```


### Add ID and language
```{r add ID and lang function, message=FALSE, warning=FALSE}
add_id <- function(playlist){
  for (i in 1:length(playlist$title)){
  song <- playlist$title[i]
  artist <- playlist$artist[i]
  g_search <- try(search_genius(paste0(song, " - ", artist))) # search the song on genius
  playlist$id[i] <- try(g_search$content[[1]]$id) # extract ID
  try(playlist$lang[i] <- g_search$content[[1]]$language) #extract language
  }
  
  return(playlist)
}
```


```{r apply function}
playlists <- lapply(playlists, add_id) # apply the function to the data

# saving to csv to be sure
all_songs <- do.call(rbind, playlists) # adding all songs to one playlist
all_songs <- all_songs %>% 
  filter(lang == "en") %>% # remove english songs
  filter(!str_detect(id, 'Error')) # remove songs that returned an error

#write_csv(all_songs, "all_songs.csv")
```

### Getting the lyrics
```{r define lyrics scraper}
lyrics_scraper <- function(df){
  lyrics_df <- NULL # initializing empty df
  for (i in 1:length(df$id)){ # looping over each song ID
    id <- df$id[i]
    lyrics <- try((get_lyrics_id(song_id = id)), silent = FALSE) # scraping lyrics
    lyrics_df <- rbind(lyrics_df, lyrics) # appending to df
  }
 return(lyrics_df)
}
```

```{r reading in playlist df, message=FALSE, warning=FALSE}
playlists_all <- read_csv("all_songs.csv")

p_1982 <- playlists_all %>% 
  filter(year == 1982) %>% 
  distinct(id, .keep_all = TRUE) # only keep unique songs

p_2002 <- playlists_all %>% 
  filter(year == 2002) %>% 
  distinct(id, .keep_all = TRUE)

p_2022 <- playlists_all %>% 
  filter(year == 2022) %>% 
  distinct(id, .keep_all = TRUE)

playlists <- list(p_1982, p_2002, p_2022)
```


```{r getting lyrics, message=FALSE, warning=FALSE}
lyrics <- lapply(playlists, lyrics_scraper)
```


### Remove wrong songs

```{r define cleaning function}
cleaner_fun <- function(df){
  df <- df %>% 
  filter(artist_name != "Spotify") %>% # remove songs where the API has returned Spotify playlists instead of songs
  filter(!str_detect(song_id, 'Error')) %>% # remove songs where the API has returned errors
  filter(!str_detect(artist_name, 'Genius')) %>% # remove songs where the API has returned Genius playlists or translations instead of the real song
  drop_na()
  
  return(df)
}

lyrics <- lapply(lyrics, cleaner_fun)
```

### Listing the ID's to the songs that have returned wrong results and removing them
Some wrong songs could not be captured by the above cleaning function, and I have thus by visual inspection identified them as errornous.

```{r remove wrong results}
remove_82 <- c("6868363","4033274","480443","748742","581048","467863","491080","387797","297338","1868856","504292","2644622","5461894","2831404")

remove_02 <- c("2422119", "3299443", "8176969", "409534", "3038244", "3038244")

remove_22 <- c("7559954", "7507324", "7457331", "8687863", "8631841", "8451026", "7130381")

# removing the songs
lyrics[[1]] <- lyrics[[1]] %>% 
  filter(! song_id %in% remove_82)

lyrics[[2]] <- lyrics[[2]] %>% 
  filter(! song_id %in% remove_02)

lyrics[[3]] <- lyrics[[3]] %>% 
  filter(! song_id %in% remove_22)
```

### Writing the final df's to csv files
```{r write to csv}
#write.csv(lyrics[[1]], "lyrics_1982.csv")
#write.csv(lyrics[[2]], "lyrics_2002.csv")
#write.csv(lyrics[[3]], "lyrics_2022.csv")
```

