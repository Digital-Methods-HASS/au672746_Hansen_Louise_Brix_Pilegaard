---
title: "got_textmining"
author: "Louise Brix Pilegaard Hansen"
date: '2022-11-08'
output: html_document
---

# 1) Reproduce the code in the repository and extend it following the suggestion (e.g., assess and consider the sentiment in the Game of Thrones) or your own body of text


I am using the code and pipeline from the "W11.Rmd" file and applying it on the Game of Thrones PDF.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(here)

# For text mining:
library(pdftools)
library(tidytext)
library(textdata) 
library(ggwordcloud)
```

### loading the pdf file
```{r}
got_path <- here("homework/week 8/data","got.pdf")
got_text <- pdf_text(got_path)
```

### Splitting up the texts
```{r}
got_df <- data.frame(got_text) %>% 
  mutate(text_full = str_split(got_text, pattern = '\\n')) %>% 
  unnest(text_full) %>% 
  mutate(text_full = str_trim(text_full)) 
```

### tokenizing
```{r}
got_tokens <- got_df %>% 
  unnest_tokens(word, text_full)

# counting words
got_wc <- got_tokens %>% 
  count(word) %>% 
  arrange(-n)
got_wc
```

### remove stopwords

```{r}
got_stop <- got_tokens %>% 
  anti_join(stop_words) %>% 
  select(-got_text)

got_swc <- got_stop %>% 
  count(word) %>% 
  arrange(-n)
```

### Remove numbers and the word 'chapter'
```{r}
got_no_numeric <- got_stop %>% 
  filter(is.na(as.numeric(word)))

# removing the word "chapter" as it is just in the preface of the book

got_no_numeric_2 <- got_no_numeric %>% 
  filter(word != "chapter")
```
### finding unique words and filter by most frequent
```{r}
length(unique(got_no_numeric_2$word))

# We probably don't want to include them all in a word cloud. Let's filter to only include the top 100 most frequent?
got_top100 <- got_no_numeric_2 %>% 
  count(word) %>% 
  arrange(-n) %>% 
  head(100)
```
### plotting
```{r}
ggplot(data = got_top100, aes(label = word, size = n)) +
  geom_text_wordcloud_area(aes(color = n), shape = "diamond") +
  scale_size_area(max_size = 12) +
  scale_color_gradientn(colors = c("darkgreen","blue","red")) +
  theme_minimal()
```

## Sentiment analysis using NRC

```{r}
got_nrc <- got_stop %>% 
  inner_join(get_sentiments("nrc"))
```

### looking at excluded words

```{r}
got_exclude <- got_stop %>% 
  anti_join(get_sentiments("nrc"))

# View(ipcc_exclude)

# Count to find the most excluded:
got_exclude_n <- got_exclude %>% 
  count(word, sort = TRUE)

head(got_exclude_n)
```
it excludes  9041 words (looks like many nouns and names)

### counting sentiment labels and plotting them
```{r}
got_nrc_n <- got_nrc %>% 
  count(sentiment, sort = TRUE)

# And plot them:

ggplot(data = got_nrc_n, aes(x = sentiment, y = n)) +
  geom_col()
```


### plotting by labels
```{r}
got_nrc_n5 <- got_nrc %>% 
  count(word,sentiment, sort = TRUE) %>% 
  group_by(sentiment) %>% 
  top_n(5) %>% 
  ungroup()

got_nrc_gg <- ggplot(data = got_nrc_n5, aes(x = reorder(word,n), y = n, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, ncol = 2, scales = "free") +
  coord_flip() +
  theme_minimal() +
  labs(x = "Word", y = "count")

# Show it
got_nrc_gg
```

Lord is apperantly both under "disgust", "positive", "negative", and  "trust"...


